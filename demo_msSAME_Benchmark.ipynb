{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import scipy.io as sio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit,LeaveOneOut\n",
    "from toolbox1 import PreProcessing,acc_calculate,TRCA_train,TRCA_test\n",
    "from toolbox1 import get_P,TDCA_train,TDCA_test\n",
    "from toolbox1 import get_augment_fb_noiseAfter_ms\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "def benchmark_TRCAmssame(idx_num, n_train, t_task, n_Aug, n_Neig=None):\n",
    "\n",
    "    # setting\n",
    "    freq_tmp = np.arange(8, 16, 1)\n",
    "    f_list = np.hstack((freq_tmp, freq_tmp + 0.2, freq_tmp + 0.4, freq_tmp + 0.6, freq_tmp + 0.8))\n",
    "    target_order = np.argsort(f_list)\n",
    "    f_list = f_list[target_order]\n",
    "    phase_list = np.array([\n",
    "        0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "         0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "         0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "         0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "         0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "    ])\n",
    "    subject_id = ['S'+'{:02d}'.format(idx_subject+1) for idx_subject in range(35)]\n",
    "\n",
    "    idx_num = idx_num\n",
    "    idx_subject = subject_id[idx_num]\n",
    "    sfreq = 250\n",
    "    filepath = os.path.join(filepath_ori, str(idx_subject) + '.mat')\n",
    "    num_filter = 5\n",
    "    preEEG = PreProcessing(filepath, t_begin=0.5, t_end=0.5 + 0.14 + t_task,  # t_begin=0.5+0.14, t_end=0.5+0.14+0.3\n",
    "                           fs_down=250, chans=['POZ', 'PZ', 'PO3', 'PO5', 'PO4', 'PO6', 'O1', 'OZ', 'O2'],\n",
    "                           num_filter=num_filter)\n",
    "\n",
    "    raw_data = preEEG.load_data()\n",
    "    w_pass_2d = np.array([[5, 14, 22, 30, 38], [90, 90, 90, 90, 90]])  # 70\n",
    "    w_stop_2d = np.array([[3, 12, 20, 28, 36], [92, 92, 92, 92, 92]])  # 72\n",
    "    filtered_data = preEEG.filtered_data_iir111(w_pass_2d, w_stop_2d, raw_data)\n",
    "\n",
    "    filtered_data['bank1'] = filtered_data['bank1'][:, : ,target_order,:]  # Sorted by frequency in ascending order\n",
    "    filtered_data['bank2'] = filtered_data['bank2'][:, :, target_order, :]\n",
    "    filtered_data['bank3'] = filtered_data['bank3'][:, :, target_order, :]\n",
    "    filtered_data['bank4'] = filtered_data['bank4'][:, :, target_order, :]\n",
    "    filtered_data['bank5'] = filtered_data['bank5'][:, :, target_order, :]\n",
    "\n",
    "    \"\"\"\n",
    "     Cross-validation parameters\n",
    "    \"\"\"\n",
    "    nBlock = 6\n",
    "    nEvent = 40\n",
    "    train_size = n_train  # input\n",
    "    n_splits = 6\n",
    "    if train_size == nBlock - 1 or train_size == 1:\n",
    "        kf = LeaveOneOut()\n",
    "    else:\n",
    "        kf = ShuffleSplit(n_splits=n_splits, train_size=train_size, random_state=idx_num+1)\n",
    "\n",
    "    t = t_task              # input\n",
    "    task_point = np.arange(int((0.14) * sfreq), int((0.14 + t) * sfreq))\n",
    "\n",
    "    # train\n",
    "    acc_s = 0\n",
    "    for train, test in kf.split(np.arange(nBlock)):\n",
    "        if train_size == 1:\n",
    "            train, test = test, train\n",
    "        # train : get ensembleW of banks\n",
    "        train_w = dict()\n",
    "        train_meantemp = dict()\n",
    "        for idx_filter in range(num_filter):\n",
    "            idx_filter += 1\n",
    "            bank_data = filtered_data['bank' + str(idx_filter)]\n",
    "            train_data11 = bank_data[:, :, :, train]\n",
    "            train_data = train_data11[:, task_point, :, :]  # n_channels * n_times * n_events * n_trials\n",
    "\n",
    "            if n_Aug == 0:\n",
    "                trainData_pt = train_data.copy()\n",
    "            else:\n",
    "                # Data augmentation\n",
    "                ntrail_noise = n_Aug\n",
    "                data_augment = np.zeros((train_data.shape[0], train_data.shape[1], train_data.shape[2], ntrail_noise))\n",
    "                for ievent in range(nEvent):\n",
    "                    # get Nh_strat\n",
    "                    f = f_list[ievent]\n",
    "                    for ih in range(5):\n",
    "                        ih = ih + 1\n",
    "                        if ih * f >= 8 * idx_filter:\n",
    "                            Nh_start = ih\n",
    "                            break\n",
    "                    # print('idx_filter=',idx_filter,'f=',f,'Nh_start=',Nh_start)\n",
    "                    data_augment[:, :, ievent, :] = get_augment_fb_noiseAfter_ms(fs=sfreq, f_list=f_list,\n",
    "                                                                                 phi_list=phase_list, Nh_start=Nh_start,\n",
    "                                                                                 Nh_end=5,\n",
    "                                                                                 ntrail_noise=ntrail_noise,\n",
    "                                                                                 mean_temp_all=np.mean(train_data, -1),\n",
    "                                                                                 iEvent=ievent, nTemplates=n_Neig)\n",
    "                trainData_pt = np.concatenate((train_data, data_augment), axis=3)\n",
    "\n",
    "            # train\n",
    "            w, mean_temp = TRCA_train(trainData_pt)\n",
    "            train_w['bank' + str(idx_filter)] = w\n",
    "            train_meantemp['bank' + str(idx_filter)] = mean_temp\n",
    "\n",
    "        # test:\n",
    "        predictAll = np.zeros((test.shape[0], nEvent),int)\n",
    "        flag = 0\n",
    "        for isplit in test:\n",
    "            rrall = np.zeros((nEvent, nEvent))\n",
    "            for idx_filter in range(num_filter):\n",
    "                idx_filter += 1\n",
    "                bank_data = filtered_data['bank' + str(idx_filter)]\n",
    "                test_data = bank_data[:, :, :, isplit]\n",
    "                test_data = test_data[:, task_point, :]\n",
    "                rr = TRCA_test(test_data, train_w['bank' + str(idx_filter)],\n",
    "                               train_meantemp['bank' + str(idx_filter)], True)\n",
    "                rrall += np.multiply(np.sign(rr), (rr ** 2)) * (idx_filter ** (-1.25) + 0.25)\n",
    "            predict = np.argmax(rrall, -1)\n",
    "            predictAll[flag, :] = predict\n",
    "            flag += 1\n",
    "        acc_s = acc_calculate(predictAll) + acc_s\n",
    "    acc = acc_s / n_splits\n",
    "    print('sub', idx_num + 1, ', acc = ', acc_s / n_splits)\n",
    "    return acc\n",
    "\n",
    "def benchmark_TDCAmssame(idx_num, n_train, t_task, n_Aug, n_Neig=None):\n",
    "\n",
    "    # setting\n",
    "    freq_tmp = np.arange(8, 16, 1)\n",
    "    f_list = np.hstack((freq_tmp, freq_tmp + 0.2, freq_tmp + 0.4, freq_tmp + 0.6, freq_tmp + 0.8))\n",
    "    target_order = np.argsort(f_list)\n",
    "    f_list = f_list[target_order]\n",
    "    phase_list = np.array([\n",
    "        0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "         0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "         0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "         0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "         0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "    ])\n",
    "    subject_id = ['S'+'{:02d}'.format(idx_subject+1) for idx_subject in range(35)]\n",
    "\n",
    "    idx_num = idx_num\n",
    "    idx_subject = subject_id[idx_num]\n",
    "    sfreq = 250\n",
    "    filepath = os.path.join(filepath_ori, str(idx_subject) + '.mat')\n",
    "    num_filter = 5\n",
    "    preEEG = PreProcessing(filepath, t_begin=0.5, t_end=0.5 + 0.14 + t_task + 5/sfreq,\n",
    "                           fs_down=250, chans=['POZ', 'PZ', 'PO3', 'PO5', 'PO4', 'PO6', 'O1', 'OZ', 'O2'],\n",
    "                           num_filter=num_filter)\n",
    "\n",
    "    raw_data = preEEG.load_data()\n",
    "    w_pass_2d = np.array([[5, 14, 22, 30, 38], [90, 90, 90, 90, 90]])\n",
    "    w_stop_2d = np.array([[3, 12, 20, 28, 36], [92, 92, 92, 92, 92]])\n",
    "    filtered_data = preEEG.filtered_data_iir111(w_pass_2d, w_stop_2d, raw_data)\n",
    "\n",
    "    filtered_data['bank1'] = filtered_data['bank1'][:, : ,target_order,:]  # Sorted by frequency in ascending order\n",
    "    filtered_data['bank2'] = filtered_data['bank2'][:, :, target_order, :]\n",
    "    filtered_data['bank3'] = filtered_data['bank3'][:, :, target_order, :]\n",
    "    filtered_data['bank4'] = filtered_data['bank4'][:, :, target_order, :]\n",
    "    filtered_data['bank5'] = filtered_data['bank5'][:, :, target_order, :]\n",
    "\n",
    "    \"\"\"\n",
    "     Cross-validation parameters\n",
    "    \"\"\"\n",
    "    nBlock = 6\n",
    "    nEvent = 40\n",
    "    train_size = n_train   # input\n",
    "    n_splits = 6\n",
    "    if train_size == nBlock - 1 or train_size == 1:\n",
    "        kf = LeaveOneOut()\n",
    "    else:\n",
    "        kf = ShuffleSplit(n_splits=n_splits, train_size=train_size, random_state=idx_num+1)\n",
    "\n",
    "    \"\"\"\n",
    "    TDCA parameters\n",
    "    \"\"\"\n",
    "    l = 5  # delay point for TDCA\n",
    "    sTime = t_task        #   input\n",
    "    train_point  = np.arange(int((0.14) * sfreq), int((0.14 + sTime) * sfreq)+l)\n",
    "    test_point = np.arange(int((0.14) * sfreq), int((0.14 + sTime) * sfreq))\n",
    "    # Obtain the projection matrix P of all classes\n",
    "    P = get_P(f_list=f_list, Nh=5, sTime=sTime, sfreq=sfreq)\n",
    "\n",
    "    # train4\n",
    "    acc_s = 0\n",
    "    for train, test in kf.split(np.arange(nBlock)):\n",
    "        if train_size == 1:\n",
    "            train, test = test, train\n",
    "        # train : get ensembleW of banks\n",
    "        train_w = dict()\n",
    "        train_meantemp = dict()\n",
    "        for idx_filter in range(num_filter):\n",
    "            idx_filter += 1\n",
    "            bank_data = filtered_data['bank' + str(idx_filter)]\n",
    "            train_data11 = bank_data[:, :, :, train]\n",
    "            train_data = train_data11[:, train_point, :, :]  # n_channels * n_times * n_events * n_trials\n",
    "\n",
    "            if n_Aug == 0:\n",
    "                trainData_pt = train_data.copy()\n",
    "            else:\n",
    "                # Data augmentation\n",
    "                ntrail_noise = n_Aug\n",
    "                data_augment = np.zeros((train_data.shape[0], train_data.shape[1], train_data.shape[2], ntrail_noise))\n",
    "                for ievent in range(nEvent):\n",
    "                    # get Nh_strat\n",
    "                    f = f_list[ievent]\n",
    "                    for ih in range(5):\n",
    "                        ih = ih + 1\n",
    "                        if ih * f >= 8 * idx_filter:\n",
    "                            Nh_start = ih\n",
    "                            break\n",
    "                    data_augment[:, :, ievent, :] = get_augment_fb_noiseAfter_ms(fs=sfreq, f_list=f_list,\n",
    "                                                                                 phi_list=phase_list, Nh_start=Nh_start,\n",
    "                                                                                 Nh_end=5,\n",
    "                                                                                 ntrail_noise=ntrail_noise,\n",
    "                                                                                 mean_temp_all=np.mean(train_data, -1),\n",
    "                                                                                 iEvent=ievent, nTemplates=n_Neig)\n",
    "                trainData_pt = np.concatenate((train_data, data_augment), axis=3)\n",
    "\n",
    "            # train\n",
    "            w, mean_temp_TDCA = TDCA_train(trainData_pt, P=P, l=l, Nk=8)\n",
    "            train_w['bank' + str(idx_filter)] = w\n",
    "            train_meantemp['bank' + str(idx_filter)] = mean_temp_TDCA\n",
    "\n",
    "        # test:\n",
    "        predictAll = np.zeros((test.shape[0], nEvent),int)\n",
    "        flag = 0\n",
    "        for isplit in test:\n",
    "            rrall = np.zeros((nEvent, nEvent))\n",
    "            for idx_filter in range(num_filter):\n",
    "                idx_filter += 1\n",
    "                bank_data = filtered_data['bank' + str(idx_filter)]\n",
    "                test_data111 = bank_data[:, :, :, isplit]\n",
    "                test_data = test_data111[:,test_point,:]\n",
    "                rr = TDCA_test(test_data, train_w['bank' + str(idx_filter)], train_meantemp['bank' + str(idx_filter)],\n",
    "                               P=P, l=l)\n",
    "                rrall += np.multiply(np.sign(rr), (rr ** 2)) * (idx_filter ** (-1.25) + 0.25)\n",
    "            predict = np.argmax(rrall, -1)\n",
    "            predictAll[flag, :] = predict\n",
    "            flag += 1\n",
    "        acc_s = acc_calculate(predictAll) + acc_s\n",
    "    acc = acc_s / n_splits\n",
    "    print('sub', idx_num + 1, ', acc = ', acc_s / n_splits)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting\n",
    "n_subjects = 35\n",
    "Train_size_list = [1,2,3,4,5]\n",
    "nAug_list=[3,4,5,5,7]\n",
    "t_task_list = [0.5]\n",
    "# nNeig_list = [i*2 for i in range(21)]\n",
    "filepath_ori = '/mnt/Bench'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eTRCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eTRCA withoutSAME is executing...\n",
      "n_times= 0.5 ;n_trian= 1 ;mean_acc= 0.10002380952380951 ; running time= 122.80278158187866\n",
      "n_times= 0.5 ;n_trian= 2 ;mean_acc= 0.5757440476190476 ; running time= 102.6675329208374\n",
      "n_times= 0.5 ;n_trian= 3 ;mean_acc= 0.6994047619047619 ; running time= 91.52503418922424\n",
      "n_times= 0.5 ;n_trian= 4 ;mean_acc= 0.7591666666666667 ; running time= 66.55765581130981\n",
      "n_times= 0.5 ;n_trian= 5 ;mean_acc= 0.7929761904761906 ; running time= 49.36817502975464\n"
     ]
    }
   ],
   "source": [
    "######## eTRCA withoutSAME ########\n",
    "print('eTRCA withoutSAME is executing...')\n",
    "# acc = benchmark_TRCAmssame(idx_num=14, n_train = 3 ,t_task=0.5, n_Aug=0)\n",
    "acc_all = np.zeros((n_subjects,len(Train_size_list),len(t_task_list)))\n",
    "for i, i_times in enumerate(t_task_list):\n",
    "    for j ,j_train in enumerate(Train_size_list):\n",
    "        T1 = time.time()\n",
    "        acc = Parallel(n_jobs=-1)(delayed(benchmark_TRCAmssame)(idx_num, n_train=j_train, t_task=i_times,n_Aug=0) for idx_num in range(n_subjects))\n",
    "        acc = np.array(acc)\n",
    "        acc_all[:,j,i] = acc\n",
    "        T2 = time.time()\n",
    "        print('n_times=',i_times,';n_trian=',j_train,';mean_acc=',np.mean(acc),'; running time=',T2 - T1)\n",
    "# sio.savemat(r'bench_eTRCA_acc.mat', {'acc': acc_all})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eTRCA(w/SAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eTRCA with SAME is executing...\n",
      "n_times= 0.5 ;n_trian= 1 ;mean_acc= 0.6005952380952381 ; running time= 129.91607546806335\n",
      "n_times= 0.5 ;n_trian= 2 ;mean_acc= 0.7397321428571428 ; running time= 110.95805764198303\n",
      "n_times= 0.5 ;n_trian= 3 ;mean_acc= 0.7946031746031746 ; running time= 95.50911235809326\n",
      "n_times= 0.5 ;n_trian= 4 ;mean_acc= 0.8216071428571426 ; running time= 75.88654851913452\n",
      "n_times= 0.5 ;n_trian= 5 ;mean_acc= 0.8420238095238096 ; running time= 68.34845638275146\n"
     ]
    }
   ],
   "source": [
    "######## eTRCA with SAME ########\n",
    "print('eTRCA with SAME is executing...')\n",
    "# acc = benchmark_TRCAmssame(idx_num=14, n_train = 3 ,t_task=0.5, n_Aug=nAug_list[2],n_Neig=0)\n",
    "acc_all = np.zeros((n_subjects,len(Train_size_list),len(t_task_list)))\n",
    "for i, i_times in enumerate(t_task_list):\n",
    "    for j ,j_train in enumerate(Train_size_list):\n",
    "        T1 = time.time()\n",
    "        acc = Parallel(n_jobs=-1)(delayed(benchmark_TRCAmssame)(idx_num, n_train=j_train, t_task=i_times,n_Aug=nAug_list[j],n_Neig=0) for idx_num in range(n_subjects))\n",
    "        acc = np.array(acc)\n",
    "        acc_all[:,j,i] = acc\n",
    "        T2 = time.time()\n",
    "        print('n_times=',i_times,';n_trian=',j_train,';mean_acc=',np.mean(acc),'; running time=',T2 - T1)\n",
    "# sio.savemat(r'bench_eTRCA_SAME_acc.mat', {'acc': acc_all})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eTRCA(w/msSAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eTRCA with msSAME is executing...\n",
      "n_times= 0.5 ;n_trian= 1 ;mean_acc= 0.7166666666666668 ; running time= 141.05468153953552\n",
      "n_times= 0.5 ;n_trian= 2 ;mean_acc= 0.7786904761904762 ; running time= 117.51873183250427\n",
      "n_times= 0.5 ;n_trian= 3 ;mean_acc= 0.8083730158730158 ; running time= 96.20761823654175\n",
      "n_times= 0.5 ;n_trian= 4 ;mean_acc= 0.8241666666666667 ; running time= 96.23084568977356\n",
      "n_times= 0.5 ;n_trian= 5 ;mean_acc= 0.8354761904761904 ; running time= 73.35704922676086\n"
     ]
    }
   ],
   "source": [
    "######## eTRCA with msSAME ########\n",
    "print('eTRCA with msSAME is executing...')\n",
    "# acc = benchmark_TRCAmssame(idx_num=14, n_train = 3 ,t_task=0.5, n_Aug=nAug_list[2],n_Neig=12)\n",
    "acc_all = np.zeros((n_subjects,len(Train_size_list),len(t_task_list)))\n",
    "for i, i_times in enumerate(t_task_list):\n",
    "    for j ,j_train in enumerate(Train_size_list):\n",
    "        T1 = time.time()\n",
    "        acc = Parallel(n_jobs=-1)(delayed(benchmark_TRCAmssame)(idx_num, n_train=j_train, t_task=i_times,n_Aug=nAug_list[j],n_Neig=12) for idx_num in range(n_subjects))\n",
    "        acc = np.array(acc)\n",
    "        acc_all[:,j,i] = acc\n",
    "        T2 = time.time()\n",
    "        print('n_times=',i_times,';n_trian=',j_train,';mean_acc=',np.mean(acc),'; running time=',T2 - T1)\n",
    "# sio.savemat(r'bench_eTRCA_msSAME_acc.mat', {'acc': acc_all})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDCA withoutSAME is executing...\n",
      "n_times= 0.5 ;n_trian= 1 ;mean_acc= 0.16814285714285715 ; running time= 1787.8970699310303\n",
      "n_times= 0.5 ;n_trian= 2 ;mean_acc= 0.7411607142857143 ; running time= 1497.8953742980957\n",
      "n_times= 0.5 ;n_trian= 3 ;mean_acc= 0.8076190476190476 ; running time= 1117.550154209137\n",
      "n_times= 0.5 ;n_trian= 4 ;mean_acc= 0.8401190476190475 ; running time= 771.7164487838745\n",
      "n_times= 0.5 ;n_trian= 5 ;mean_acc= 0.8570238095238095 ; running time= 444.0344326496124\n"
     ]
    }
   ],
   "source": [
    "######## TDCA withoutSAME ########\n",
    "print('TDCA withoutSAME is executing...')\n",
    "# acc = benchmark_TDCAmssame(idx_num=14, n_train = 3 ,t_task=0.5, n_Aug=0)\n",
    "acc_all = np.zeros((n_subjects,len(Train_size_list),len(t_task_list)))\n",
    "for i, i_times in enumerate(t_task_list):\n",
    "    for j ,j_train in enumerate(Train_size_list):\n",
    "        T1 = time.time()\n",
    "        acc = Parallel(n_jobs=-1)(delayed(benchmark_TDCAmssame)(idx_num, n_train=j_train, t_task=i_times,n_Aug=0) for idx_num in range(n_subjects))\n",
    "        acc = np.array(acc)\n",
    "        acc_all[:,j,i] = acc\n",
    "        T2 = time.time()\n",
    "        print('n_times=',i_times,';n_trian=',j_train,';mean_acc=',np.mean(acc),'; running time=',T2 - T1)\n",
    "# sio.savemat(r'bench_TDCA_acc.mat', {'acc': acc_all})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDCA(w/SAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDCA with SAME is executing...\n",
      "n_times= 0.5 ;n_trian= 1 ;mean_acc= 0.6491428571428572 ; running time= 1807.162671327591\n",
      "n_times= 0.5 ;n_trian= 2 ;mean_acc= 0.7789583333333334 ; running time= 1477.968709230423\n",
      "n_times= 0.5 ;n_trian= 3 ;mean_acc= 0.8252380952380953 ; running time= 1136.2217450141907\n",
      "n_times= 0.5 ;n_trian= 4 ;mean_acc= 0.8511309523809524 ; running time= 779.7826581001282\n",
      "n_times= 0.5 ;n_trian= 5 ;mean_acc= 0.8642857142857142 ; running time= 492.77216386795044\n"
     ]
    }
   ],
   "source": [
    "######## TDCA with SAME ########\n",
    "print('TDCA with SAME is executing...')\n",
    "# acc = benchmark_TDCAmssame(idx_num=14, n_train = 3 ,t_task=0.5, n_Aug=nAug_list[2],n_Neig=0)\n",
    "acc_all = np.zeros((n_subjects,len(Train_size_list),len(t_task_list)))\n",
    "for i, i_times in enumerate(t_task_list):\n",
    "    for j ,j_train in enumerate(Train_size_list):\n",
    "        T1 = time.time()\n",
    "        acc = Parallel(n_jobs=-1)(delayed(benchmark_TDCAmssame)(idx_num, n_train=j_train, t_task=i_times,n_Aug=nAug_list[j],n_Neig=0) for idx_num in range(n_subjects))\n",
    "        acc = np.array(acc)\n",
    "        acc_all[:,j,i] = acc\n",
    "        T2 = time.time()\n",
    "        print('n_times=',i_times,';n_trian=',j_train,';mean_acc=',np.mean(acc),'; running time=',T2 - T1)\n",
    "# sio.savemat(r'bench_TDCA_SAME_acc.mat', {'acc': acc_all})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDCA(w/msSAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDCA with msSAME is executing...\n",
      "n_times= 0.5 ;n_trian= 1 ;mean_acc= 0.7691666666666666 ; running time= 1693.8621637821198\n",
      "n_times= 0.5 ;n_trian= 2 ;mean_acc= 0.8282440476190476 ; running time= 1398.0316352844238\n",
      "n_times= 0.5 ;n_trian= 3 ;mean_acc= 0.8539682539682539 ; running time= 1093.1004683971405\n",
      "n_times= 0.5 ;n_trian= 4 ;mean_acc= 0.8688095238095238 ; running time= 782.0254456996918\n",
      "n_times= 0.5 ;n_trian= 5 ;mean_acc= 0.8752380952380953 ; running time= 496.7567539215088\n"
     ]
    }
   ],
   "source": [
    "######## TDCA with msSAME ########\n",
    "print('TDCA with msSAME is executing...')\n",
    "# acc = benchmark_TDCAmssame(idx_num=14, n_train = 3 ,t_task=0.5, n_Aug=nAug_list[2],n_Neig=14)\n",
    "acc_all = np.zeros((n_subjects,len(Train_size_list),len(t_task_list)))\n",
    "for i, i_times in enumerate(t_task_list):\n",
    "    for j ,j_train in enumerate(Train_size_list):\n",
    "        T1 = time.time()\n",
    "        acc = Parallel(n_jobs=-1)(delayed(benchmark_TDCAmssame)(idx_num, n_train=j_train, t_task=i_times,n_Aug=nAug_list[j],n_Neig=14) for idx_num in range(n_subjects))\n",
    "        acc = np.array(acc)\n",
    "        acc_all[:,j,i] = acc\n",
    "        T2 = time.time()\n",
    "        print('n_times=',i_times,';n_trian=',j_train,';mean_acc=',np.mean(acc),'; running time=',T2 - T1)\n",
    "# sio.savemat(r'bench_TDCA_msSAME_acc.mat', {'acc': acc_all})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
