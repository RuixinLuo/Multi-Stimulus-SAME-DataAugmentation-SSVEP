{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import scipy.io as sio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit,LeaveOneOut\n",
    "from toolbox1 import PreProcessing_BETA,acc_calculate,TRCA_train,TRCA_test\n",
    "from toolbox1 import get_P,TDCA_train,TDCA_test\n",
    "from toolbox1 import get_augment_fb_noiseAfter_ms\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "def BETA_TRCAmssame(idx_num, n_train, t_task, n_Aug, n_Neig=None):\n",
    "\n",
    "    # setting\n",
    "    f_list = np.array([8.6, 8.8,\n",
    "              9, 9.2, 9.4, 9.6, 9.8,\n",
    "              10, 10.2, 10.4, 10.6, 10.8,\n",
    "              11, 11.2, 11.4, 11.6, 11.8,\n",
    "              12, 12.2, 12.4, 12.6, 12.8,\n",
    "              13, 13.2, 13.4, 13.6, 13.8,\n",
    "              14, 14.2, 14.4, 14.6, 14.8,\n",
    "              15, 15.2, 15.4, 15.6, 15.8,\n",
    "              8, 8.2, 8.4, ])\n",
    "    target_order = np.argsort(f_list)\n",
    "    f_list = f_list[target_order]\n",
    "    phase_list = np.array([\n",
    "        0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "         0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "         0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "         0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "         0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "    ])\n",
    "    subject_id = ['S'+'{:02d}'.format(idx_subject+1) for idx_subject in range(70)]\n",
    "\n",
    "    idx_num = idx_num\n",
    "    idx_subject = subject_id[idx_num]\n",
    "    sfreq = 250\n",
    "    filepath = os.path.join(filepath_ori, str(idx_subject) + '.mat')\n",
    "    num_filter = 5\n",
    "    preEEG = PreProcessing_BETA(filepath, t_begin=0.5, t_end=0.5 + 0.13 + t_task,  # t_begin=0.5+0.14, t_end=0.5+0.14+0.3\n",
    "                           fs_down=250, chans=['POZ', 'PZ', 'PO3', 'PO5', 'PO4', 'PO6', 'O1', 'OZ', 'O2'],\n",
    "                           num_filter=num_filter)\n",
    "\n",
    "    raw_data = preEEG.load_data()\n",
    "    w_pass_2d = np.array([[5, 14, 22, 30, 38], [90, 90, 90, 90, 90]])  # 70\n",
    "    w_stop_2d = np.array([[3, 12, 20, 28, 36], [92, 92, 92, 92, 92]])  # 72\n",
    "    filtered_data = preEEG.filtered_data_iir111(w_pass_2d, w_stop_2d, raw_data)\n",
    "\n",
    "    filtered_data['bank1'] = filtered_data['bank1'][:, : ,target_order,:]  # Sorted by frequency in ascending order\n",
    "    filtered_data['bank2'] = filtered_data['bank2'][:, :, target_order, :]\n",
    "    filtered_data['bank3'] = filtered_data['bank3'][:, :, target_order, :]\n",
    "    filtered_data['bank4'] = filtered_data['bank4'][:, :, target_order, :]\n",
    "    filtered_data['bank5'] = filtered_data['bank5'][:, :, target_order, :]\n",
    "\n",
    "    \"\"\"\n",
    "     Cross-validation parameters\n",
    "    \"\"\"\n",
    "    nBlock = 4\n",
    "    nEvent = 40\n",
    "    train_size = n_train  # input\n",
    "    n_splits = 4\n",
    "    if train_size == nBlock - 1 or train_size == 1:\n",
    "        kf = LeaveOneOut()\n",
    "    else:\n",
    "        kf = ShuffleSplit(n_splits=n_splits, train_size=train_size, random_state=idx_num+1)\n",
    "\n",
    "    t = t_task              # input\n",
    "    task_point = np.arange(int((0.13) * sfreq), int((0.13 + t) * sfreq))\n",
    "\n",
    "    # train\n",
    "    acc_s = 0\n",
    "    for train, test in kf.split(np.arange(nBlock)):\n",
    "        if train_size == 1:\n",
    "            train, test = test, train\n",
    "        # train : get ensembleW of banks\n",
    "        train_w = dict()\n",
    "        train_meantemp = dict()\n",
    "        for idx_filter in range(num_filter):\n",
    "            idx_filter += 1\n",
    "            bank_data = filtered_data['bank' + str(idx_filter)]\n",
    "            train_data11 = bank_data[:, :, :, train]\n",
    "            train_data = train_data11[:, task_point, :, :]  # n_channels * n_times * n_events * n_trials\n",
    "\n",
    "            if n_Aug == 0:\n",
    "                trainData_pt = train_data.copy()\n",
    "            else:\n",
    "                # Data augmentation\n",
    "                ntrail_noise = n_Aug\n",
    "                data_augment = np.zeros((train_data.shape[0], train_data.shape[1], train_data.shape[2], ntrail_noise))\n",
    "                for ievent in range(nEvent):\n",
    "                    # get Nh_strat\n",
    "                    f = f_list[ievent]\n",
    "                    for ih in range(5):\n",
    "                        ih = ih + 1\n",
    "                        if ih * f >= 8 * idx_filter:\n",
    "                            Nh_start = ih\n",
    "                            break\n",
    "                    data_augment[:, :, ievent, :] = get_augment_fb_noiseAfter_ms(fs=sfreq, f_list=f_list,\n",
    "                                                                                 phi_list=phase_list, Nh_start=Nh_start,\n",
    "                                                                                 Nh_end=5,\n",
    "                                                                                 ntrail_noise=ntrail_noise,\n",
    "                                                                                 mean_temp_all=np.mean(train_data, -1),\n",
    "                                                                                 iEvent=ievent, nTemplates=n_Neig)\n",
    "                trainData_pt = np.concatenate((train_data, data_augment), axis=3)\n",
    "\n",
    "            # train\n",
    "            w, mean_temp = TRCA_train(trainData_pt)\n",
    "            train_w['bank' + str(idx_filter)] = w\n",
    "            train_meantemp['bank' + str(idx_filter)] = mean_temp\n",
    "\n",
    "        # test:\n",
    "        predictAll = np.zeros((test.shape[0], nEvent),int)\n",
    "        flag = 0\n",
    "        for isplit in test:\n",
    "            rrall = np.zeros((nEvent, nEvent))\n",
    "            for idx_filter in range(num_filter):\n",
    "                idx_filter += 1\n",
    "                bank_data = filtered_data['bank' + str(idx_filter)]\n",
    "                test_data = bank_data[:, :, :, isplit]\n",
    "                test_data = test_data[:, task_point, :]\n",
    "                rr = TRCA_test(test_data, train_w['bank' + str(idx_filter)],\n",
    "                               train_meantemp['bank' + str(idx_filter)], True)\n",
    "                rrall += np.multiply(np.sign(rr), (rr ** 2)) * (idx_filter ** (-1.25) + 0.25)\n",
    "            predict = np.argmax(rrall, -1)\n",
    "            predictAll[flag, :] = predict\n",
    "            flag += 1\n",
    "        acc_s = acc_calculate(predictAll) + acc_s\n",
    "    acc = acc_s / n_splits\n",
    "    print('sub', idx_num + 1, ', acc = ', acc_s / n_splits)\n",
    "    return acc\n",
    "\n",
    "def BETA_TDCAmssame(idx_num, n_train, t_task, n_Aug, n_Neig=None):\n",
    "\n",
    "    # setting\n",
    "    f_list = np.array([8.6, 8.8,\n",
    "              9, 9.2, 9.4, 9.6, 9.8,\n",
    "              10, 10.2, 10.4, 10.6, 10.8,\n",
    "              11, 11.2, 11.4, 11.6, 11.8,\n",
    "              12, 12.2, 12.4, 12.6, 12.8,\n",
    "              13, 13.2, 13.4, 13.6, 13.8,\n",
    "              14, 14.2, 14.4, 14.6, 14.8,\n",
    "              15, 15.2, 15.4, 15.6, 15.8,\n",
    "              8, 8.2, 8.4, ])\n",
    "    target_order = np.argsort(f_list)\n",
    "    f_list = f_list[target_order]\n",
    "    phase_list = np.array([\n",
    "        0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "         0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "         0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "         0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "         0, 0.5, 1, 1.5, 0, 0.5, 1, 1.5,\n",
    "    ])\n",
    "    subject_id = ['S'+'{:02d}'.format(idx_subject+1) for idx_subject in range(70)]\n",
    "\n",
    "    idx_num = idx_num\n",
    "    idx_subject = subject_id[idx_num]\n",
    "    sfreq = 250\n",
    "    filepath = os.path.join(filepath_ori, str(idx_subject) + '.mat')\n",
    "    num_filter = 5\n",
    "    preEEG = PreProcessing_BETA(filepath, t_begin=0.5, t_end=0.5 + 0.13 + t_task + 3/sfreq,\n",
    "                           fs_down=250, chans=['POZ', 'PZ', 'PO3', 'PO5', 'PO4', 'PO6', 'O1', 'OZ', 'O2'],\n",
    "                           num_filter=num_filter)\n",
    "\n",
    "    raw_data = preEEG.load_data()\n",
    "    w_pass_2d = np.array([[5, 14, 22, 30, 38], [90, 90, 90, 90, 90]])\n",
    "    w_stop_2d = np.array([[3, 12, 20, 28, 36], [92, 92, 92, 92, 92]])\n",
    "    filtered_data = preEEG.filtered_data_iir111(w_pass_2d, w_stop_2d, raw_data)\n",
    "\n",
    "    filtered_data['bank1'] = filtered_data['bank1'][:, : ,target_order,:]  # Sorted by frequency in ascending order\n",
    "    filtered_data['bank2'] = filtered_data['bank2'][:, :, target_order, :]\n",
    "    filtered_data['bank3'] = filtered_data['bank3'][:, :, target_order, :]\n",
    "    filtered_data['bank4'] = filtered_data['bank4'][:, :, target_order, :]\n",
    "    filtered_data['bank5'] = filtered_data['bank5'][:, :, target_order, :]\n",
    "\n",
    "    \"\"\"\n",
    "     Cross-validation parameters\n",
    "    \"\"\"\n",
    "    nBlock = 4\n",
    "    nEvent = 40\n",
    "    train_size = n_train   # input\n",
    "    n_splits = 4\n",
    "    if train_size == nBlock - 1 or train_size == 1:\n",
    "        kf = LeaveOneOut()\n",
    "    else:\n",
    "        kf = ShuffleSplit(n_splits=n_splits, train_size=train_size, random_state=idx_num+1)\n",
    "\n",
    "    \"\"\"\n",
    "    TDCA parameters\n",
    "    \"\"\"\n",
    "    l = 3  # delay point for TDCA\n",
    "    sTime = t_task        #   input\n",
    "    train_point  = np.arange(int((0.13) * sfreq), int((0.13 + sTime) * sfreq)+l)\n",
    "    test_point = np.arange(int((0.13) * sfreq), int((0.13 + sTime) * sfreq))\n",
    "    # Obtain the projection matrix P of all classes\n",
    "    P = get_P(f_list=f_list, Nh=5, sTime=sTime, sfreq=sfreq)\n",
    "\n",
    "    # train4\n",
    "    acc_s = 0\n",
    "    for train, test in kf.split(np.arange(nBlock)):\n",
    "        if train_size == 1:\n",
    "            train, test = test, train\n",
    "        # train : get ensembleW of banks\n",
    "        train_w = dict()\n",
    "        train_meantemp = dict()\n",
    "        for idx_filter in range(num_filter):\n",
    "            idx_filter += 1\n",
    "            bank_data = filtered_data['bank' + str(idx_filter)]\n",
    "            train_data11 = bank_data[:, :, :, train]\n",
    "            train_data = train_data11[:, train_point, :, :]  # n_channels * n_times * n_events * n_trials\n",
    "\n",
    "            if n_Aug == 0:\n",
    "                trainData_pt = train_data.copy()\n",
    "            else:\n",
    "                # Data augmentation\n",
    "                ntrail_noise = n_Aug\n",
    "                data_augment = np.zeros((train_data.shape[0], train_data.shape[1], train_data.shape[2], ntrail_noise))\n",
    "                for ievent in range(nEvent):\n",
    "                    # get Nh_strat\n",
    "                    f = f_list[ievent]\n",
    "                    for ih in range(5):\n",
    "                        ih = ih + 1\n",
    "                        if ih * f >= 8 * idx_filter:\n",
    "                            Nh_start = ih\n",
    "                            break\n",
    "                    data_augment[:, :, ievent, :] = get_augment_fb_noiseAfter_ms(fs=sfreq, f_list=f_list,\n",
    "                                                                                 phi_list=phase_list, Nh_start=Nh_start,\n",
    "                                                                                 Nh_end=5,\n",
    "                                                                                 ntrail_noise=ntrail_noise,\n",
    "                                                                                 mean_temp_all=np.mean(train_data, -1),\n",
    "                                                                                 iEvent=ievent, nTemplates=n_Neig)\n",
    "                trainData_pt = np.concatenate((train_data, data_augment), axis=3)\n",
    "\n",
    "            # train\n",
    "            w, mean_temp_TDCA = TDCA_train(trainData_pt, P=P, l=l, Nk=9)\n",
    "            train_w['bank' + str(idx_filter)] = w\n",
    "            train_meantemp['bank' + str(idx_filter)] = mean_temp_TDCA\n",
    "\n",
    "        # test:\n",
    "        predictAll = np.zeros((test.shape[0], nEvent),int)\n",
    "        flag = 0\n",
    "        for isplit in test:\n",
    "            rrall = np.zeros((nEvent, nEvent))\n",
    "            for idx_filter in range(num_filter):\n",
    "                idx_filter += 1\n",
    "                bank_data = filtered_data['bank' + str(idx_filter)]\n",
    "                test_data111 = bank_data[:, :, :, isplit]\n",
    "                test_data = test_data111[:,test_point,:]\n",
    "                rr = TDCA_test(test_data, train_w['bank' + str(idx_filter)], train_meantemp['bank' + str(idx_filter)],\n",
    "                               P=P, l=l)\n",
    "                rrall += np.multiply(np.sign(rr), (rr ** 2)) * (idx_filter ** (-1.25) + 0.25)\n",
    "            predict = np.argmax(rrall, -1)\n",
    "            predictAll[flag, :] = predict\n",
    "            flag += 1\n",
    "        acc_s = acc_calculate(predictAll) + acc_s\n",
    "    acc = acc_s / n_splits\n",
    "    print('sub', idx_num + 1, ', acc = ', acc_s / n_splits)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting\n",
    "n_subjects = 70\n",
    "Train_size_list = [1,2,3]\n",
    "nAug_list=[3,5,6]\n",
    "t_task_list = [0.5]\n",
    "# nNeig_list = [i*2 for i in range(21)]\n",
    "filepath_ori = '/mnt/Beta'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eTRCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eTRCA withoutSAME is executing...\n",
      "n_times= 0.5 ;n_trian= 1 ;mean_acc= 0.12014880952380952 ; running time= 102.4008948802948\n",
      "n_times= 0.5 ;n_trian= 2 ;mean_acc= 0.5208035714285714 ; running time= 81.31394457817078\n",
      "n_times= 0.5 ;n_trian= 3 ;mean_acc= 0.609017857142857 ; running time= 54.879578828811646\n"
     ]
    }
   ],
   "source": [
    "######## eTRCA withoutSAME ########\n",
    "print('eTRCA withoutSAME is executing...')\n",
    "# acc = BETA_TRCAmssame(idx_num=57, n_train = 2 ,t_task=0.5, n_Aug=0)\n",
    "acc_all = np.zeros((n_subjects,len(Train_size_list),len(t_task_list)))\n",
    "for i, i_times in enumerate(t_task_list):\n",
    "    for j ,j_train in enumerate(Train_size_list):\n",
    "        T1 = time.time()\n",
    "        acc = Parallel(n_jobs=-1)(delayed(BETA_TRCAmssame)(idx_num, n_train=j_train, t_task=i_times,n_Aug=0) for idx_num in range(n_subjects))\n",
    "        acc = np.array(acc)\n",
    "        acc_all[:,j,i] = acc\n",
    "        T2 = time.time()\n",
    "        print('n_times=',i_times,';n_trian=',j_train,';mean_acc=',np.mean(acc),'; running time=',T2 - T1)\n",
    "# sio.savemat(r'BETA_eTRCA_acc.mat', {'acc': acc_all})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eTRCA(w/SAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eTRCA with SAME is executing...\n",
      "n_times= 0.5 ;n_trian= 1 ;mean_acc= 0.5208630952380952 ; running time= 109.84040117263794\n",
      "n_times= 0.5 ;n_trian= 2 ;mean_acc= 0.6249999999999999 ; running time= 88.12679767608643\n",
      "n_times= 0.5 ;n_trian= 3 ;mean_acc= 0.6776785714285716 ; running time= 68.85598540306091\n"
     ]
    }
   ],
   "source": [
    "######## eTRCA with SAME ########\n",
    "print('eTRCA with SAME is executing...')\n",
    "# acc = BETA_TRCAmssame(idx_num=57, n_train = 2 ,t_task=0.5, n_Aug=nAug_list[1],n_Neig=0)\n",
    "acc_all = np.zeros((n_subjects,len(Train_size_list),len(t_task_list)))\n",
    "for i, i_times in enumerate(t_task_list):\n",
    "    for j ,j_train in enumerate(Train_size_list):\n",
    "        T1 = time.time()\n",
    "        acc = Parallel(n_jobs=-1)(delayed(BETA_TRCAmssame)(idx_num, n_train=j_train, t_task=i_times,n_Aug=nAug_list[j],n_Neig=0) for idx_num in range(n_subjects))\n",
    "        acc = np.array(acc)\n",
    "        acc_all[:,j,i] = acc\n",
    "        T2 = time.time()\n",
    "        print('n_times=',i_times,';n_trian=',j_train,';mean_acc=',np.mean(acc),'; running time=',T2 - T1)\n",
    "# sio.savemat(r'BETA_eTRCA_SAME_acc.mat', {'acc': acc_all})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eTRCA(w/msSAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eTRCA with msSAME is executing...\n",
      "n_times= 0.5 ;n_trian= 1 ;mean_acc= 0.6247916666666667 ; running time= 113.67107391357422\n",
      "n_times= 0.5 ;n_trian= 2 ;mean_acc= 0.6879017857142858 ; running time= 95.79490780830383\n",
      "n_times= 0.5 ;n_trian= 3 ;mean_acc= 0.7124107142857142 ; running time= 76.81982493400574\n"
     ]
    }
   ],
   "source": [
    "######## eTRCA with msSAME ########\n",
    "print('eTRCA with msSAME is executing...')\n",
    "# acc = BETA_TRCAmssame(idx_num=57, n_train = 2 ,t_task=0.5, n_Aug=nAug_list[1],n_Neig=10)\n",
    "acc_all = np.zeros((n_subjects,len(Train_size_list),len(t_task_list)))\n",
    "for i, i_times in enumerate(t_task_list):\n",
    "    for j ,j_train in enumerate(Train_size_list):\n",
    "        T1 = time.time()\n",
    "        acc = Parallel(n_jobs=-1)(delayed(BETA_TRCAmssame)(idx_num, n_train=j_train, t_task=i_times,n_Aug=nAug_list[j],n_Neig=10) for idx_num in range(n_subjects))\n",
    "        acc = np.array(acc)\n",
    "        acc_all[:,j,i] = acc\n",
    "        T2 = time.time()\n",
    "        print('n_times=',i_times,';n_trian=',j_train,';mean_acc=',np.mean(acc),'; running time=',T2 - T1)\n",
    "# sio.savemat(r'BETA_eTRCA_msSAME_acc.mat', {'acc': acc_all})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDCA withoutSAME is executing...\n",
      "n_times= 0.5 ;n_trian= 1 ;mean_acc= 0.18431547619047617 ; running time= 923.5383055210114\n",
      "n_times= 0.5 ;n_trian= 2 ;mean_acc= 0.6082589285714286 ; running time= 643.8419704437256\n",
      "n_times= 0.5 ;n_trian= 3 ;mean_acc= 0.6830357142857142 ; running time= 354.77954363822937\n"
     ]
    }
   ],
   "source": [
    "######## TDCA withoutSAME ########\n",
    "print('TDCA withoutSAME is executing...')\n",
    "# acc = BETA_TDCAmssame(idx_num=57, n_train = 2 ,t_task=0.5, n_Aug=0)\n",
    "acc_all = np.zeros((n_subjects,len(Train_size_list),len(t_task_list)))\n",
    "for i, i_times in enumerate(t_task_list):\n",
    "    for j ,j_train in enumerate(Train_size_list):\n",
    "        T1 = time.time()\n",
    "        acc = Parallel(n_jobs=-1)(delayed(BETA_TDCAmssame)(idx_num, n_train=j_train, t_task=i_times,n_Aug=0) for idx_num in range(n_subjects))\n",
    "        acc = np.array(acc)\n",
    "        acc_all[:,j,i] = acc\n",
    "        T2 = time.time()\n",
    "        print('n_times=',i_times,';n_trian=',j_train,';mean_acc=',np.mean(acc),'; running time=',T2 - T1)\n",
    "# sio.savemat(r'BETA_TDCA_acc.mat', {'acc': acc_all})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDCA(w/SAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDCA with SAME is executing...\n",
      "n_times= 0.5 ;n_trian= 1 ;mean_acc= 0.5263690476190476 ; running time= 962.561327457428\n",
      "n_times= 0.5 ;n_trian= 2 ;mean_acc= 0.6345535714285714 ; running time= 698.0998861789703\n",
      "n_times= 0.5 ;n_trian= 3 ;mean_acc= 0.695982142857143 ; running time= 423.4984850883484\n"
     ]
    }
   ],
   "source": [
    "######## TDCA with SAME ########\n",
    "print('TDCA with SAME is executing...')\n",
    "# acc = BETA_TDCAmssame(idx_num=57, n_train = 2 ,t_task=0.5, n_Aug=nAug_list[1],n_Neig=0)\n",
    "acc_all = np.zeros((n_subjects,len(Train_size_list),len(t_task_list)))\n",
    "for i, i_times in enumerate(t_task_list):\n",
    "    for j ,j_train in enumerate(Train_size_list):\n",
    "        T1 = time.time()\n",
    "        acc = Parallel(n_jobs=-1)(delayed(BETA_TDCAmssame)(idx_num, n_train=j_train, t_task=i_times,n_Aug=nAug_list[j],n_Neig=0) for idx_num in range(n_subjects))\n",
    "        acc = np.array(acc)\n",
    "        acc_all[:,j,i] = acc\n",
    "        T2 = time.time()\n",
    "        print('n_times=',i_times,';n_trian=',j_train,';mean_acc=',np.mean(acc),'; running time=',T2 - T1)\n",
    "# sio.savemat(r'BETA_TDCA_SAME_acc.mat', {'acc': acc_all})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDCA(w/msSAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDCA with msSAME is executing...\n",
      "n_times= 0.5 ;n_trian= 1 ;mean_acc= 0.6719642857142857 ; running time= 962.2310721874237\n",
      "n_times= 0.5 ;n_trian= 2 ;mean_acc= 0.7314732142857144 ; running time= 697.8803493976593\n",
      "n_times= 0.5 ;n_trian= 3 ;mean_acc= 0.7577678571428572 ; running time= 423.3291039466858\n"
     ]
    }
   ],
   "source": [
    "######## TDCA with msSAME ########\n",
    "print('TDCA with msSAME is executing...')\n",
    "# acc = BETA_TDCAmssame(idx_num=57, n_train = 2 ,t_task=0.5, n_Aug=nAug_list[1],n_Neig=10)\n",
    "acc_all = np.zeros((n_subjects,len(Train_size_list),len(t_task_list)))\n",
    "for i, i_times in enumerate(t_task_list):\n",
    "    for j ,j_train in enumerate(Train_size_list):\n",
    "        T1 = time.time()\n",
    "        acc = Parallel(n_jobs=-1)(delayed(BETA_TDCAmssame)(idx_num, n_train=j_train, t_task=i_times,n_Aug=nAug_list[j],n_Neig=10) for idx_num in range(n_subjects))\n",
    "        acc = np.array(acc)\n",
    "        acc_all[:,j,i] = acc\n",
    "        T2 = time.time()\n",
    "        print('n_times=',i_times,';n_trian=',j_train,';mean_acc=',np.mean(acc),'; running time=',T2 - T1)\n",
    "# sio.savemat(r'BETA_TDCA_msSAME_acc.mat', {'acc': acc_all})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
